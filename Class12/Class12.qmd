---
title: "Class12"
author: "Yuntian Zhu (PID: A17816597)"
format: pdf
toc: true
---

## Backgroun
Today we will analyze some RNA-seq data on the effects of a common steroid on airway smooth muscle cells.

## Data import

```{r}
counts <- read.csv("airway_scaledcounts.csv", row.names=1)
metadata <- read.csv("airway_metadata.csv")
head(counts)
head(metadata)
```

> Q1. How many genes are in this dataset?

```{r}
nrow(counts)
```

There are 38694 genes in this dataset.

> Q. How many different experiments (columns in counts or rows in metadata) are there?

```{r}
ncol(counts)
```

> Q2. How many ‘control’ cell lines do we have? 

```{r}
sum(metadata$dex == "control")
```

We have 4 control cell lines. 

## Toy differential gene experession

To start our analysis, let's calculate the mean counts of the counts for all genes in the "control" experiments

1. Extract all "control columns from the `counts` object

2. Calculate the mean for all rows (i. e. genes) of these "control" columns

3 and 4. Do the same thing for "treated" groups

5. Compare these `control.mean` and `treated.mean` values.

Method 1:

```{r}
control <- metadata[metadata[,"dex"]=="control",]
control.counts <- counts[ ,control$id]
control.mean <- rowSums( control.counts )/4 
head(control.mean)
```

> Q3. How would you make the above code in either approach more robust? Is there a function that could help here?

The method above finds the mean by first calculate the summation and divide it by 4 (the number of samples), which is not very robust. The primary reason is that there might be a different sample number and we need to change 4 to another number by ourselves. We can improve the code by using the function `rowMeans()`. By using `rowMeans()`, the mean is calculated automatically across however many samples are present, without requiring us to hard-code the sample count. This not only makes the code more flexible and maintainable, but also reduces the risk of errors when working with different datasets or experimental designs.

```{r}
control.inds <- metadata$dex == "control"
control.count <- counts[, control.inds]
control.mean <- rowMeans(control.count)
head(control.mean)
```

> Q4. Follow the same procedure for the treated samples (i.e. calculate the mean per gene across drug treated samples and assign to a labeled vector called treated.mean)

```{r}
treated.inds <- metadata$dex == "treated"
treated.count <- counts[, treated.inds]
treated.mean <- rowMeans(treated.count)
head(treated.mean)
```

Store these all together for the ease of bookkeeping as `meancounts`

```{r}
meancounts <- data.frame(control.mean, treated.mean)
head(meancounts)
```

> Q5 (a). Create a scatter plot showing the mean of the treated samples against the mean of the control samples. 

Let us make a plot of control vs. treated mean values 

```{r}
plot(meancounts)
```

> Q5 (b).You could also use the ggplot2 package to make this figure producing the plot below. What geom_?() function would you use for this plot?

Let us make another plot using ggplot2. We should use `geom_point()` here. 

```{r}
library(ggplot2)
  ggplot(meancounts) + 
    aes(control.mean, treated.mean, alpha = 0.2) + 
    geom_point()
```

>Q6. Try plotting both axes on a log scale. What is the argument to plot() that allows you to do this?

Make this a log log plot, so that the plot gets less crowded. The argument that we should use here is `log = "xy"`.

```{r}
plot(meancounts, log = "xy")
```

We oftern talk about metrics like log2FC. Let's calculate the log2 fold change for our treated over control mean counts.

```{r}
meancounts$log2fc <-
log2(meancounts$treated.mean/
  meancounts$control.mean)
head(meancounts)
```

A common "rule of thumb" is a log2 fold change cutoff of +2 and -2 to callgenes "upregulated' or "downregulared".


First, we can find the number of upregulated genes

```{r}
sum(meancounts$log2fc >= +2, na.rm = T)
```

Then, we can find the number of downregulated genes

```{r}
sum(meancounts$log2fc >= -2, na.rm = TRUE)
```

We can make the data more polished by removing the genes that are not even expressed, so that we will not have things like NaN or -Inf.

```{r}
zero.vals <- which(meancounts[,1:2]==0, arr.ind=TRUE)

to.rm <- unique(zero.vals[,1])
mycounts <- meancounts[-to.rm,]
head(mycounts)
```

> Q7. What is the purpose of the `arr.ind` argument in the `which()` function call above? Why would we then take the first column of the output and need to call the `unique()` function?

The purpose of `arr.ind` is to get row and column coordinates instead of just linear positions, because normally, `which()` returns just the indices of TRUE values in a vector. The purpose of taking the first column is to find which rows (genes) have a zero in either control.mean or treated.mean.
The first column of `zero.vals` corresponds to the row index of each zero entry, so that we can remove any genes that have zero counts in any samples. The purpose of calling the `unique()` function is that A single row (gene) might appear multiple times if both control.mean and treated.mean are zero, or if repeated zeros are found. To avoid removing the same row multiple times, we take only unique row indices.

> Q8. Using the up.ind vector above can you determine how many up regulated genes we have at the greater than 2 fc level? 

```{r}
up.ind <- mycounts$log2fc > 2
sum(up.ind)
```

We have 250 upregulated genes at the greater than 2 fc level.

 > Q9. Using the down.ind vector above can you determine how many down regulated genes we have at the greater than 2 fc level?
 
```{r}
down.ind <- mycounts$log2fc < (-2)
sum(down.ind)
```
 
We have 367 downregulated genes at the greater than 2 fc level.

> Q10. Do you trust these results? Why or why not?

Not really. The results only reflect whether the log2FC of a certain gene is greater than the 2 cutoff or less than the -2 cutoff. In order to make the result more trustable, we should focus on the genes that show statistically significant change. In other words, we should also consider the p-values in addition to log2FC. Then, we can focus on the genes that not only have log2FC > 2 or log2FC < -2 but also have a small p-value showing the statistical significance. 

## DESeq2 analysis

Let;s do this analysis properly and find genes that have a statistically significant change. 

```{r, message = FALSE}
library(DESeq2)
```

For DESeq analysis, we need three things:

- count values (`countData`)
- metadata telling us about hte columns in `countData` (`colData`)
- design of the experiment (i. e. what do you want to compare)

Our first function from DESeq2 will set up the input for our analysis by storing all these three things together. 

```{r}
dds <- DESeqDataSetFromMatrix(countData = counts,
                              colData = metadata,
                              design = ~dex)
```

The main function in DESeq2 that runs the differential expression analysis is called `DESeq()`

```{r}
dds <- DESeq(dds)
```

```{r}
res <- results(dds)
head(res)
```

## Volcano Plot

This is a common summery result figure from these types of experiments an plot the log2 fold-change vs the adjusted p-value

```{r}
plot(res$log2FoldChange, -log(res$padj))
abline(v = c(-2, 2), col = "red")
abline(h = -log(0.05), col = "red")
```

## Save our results

```{r}
write.csv(res, file = "myresults.csv")
```

## Add gene annotation

To help make sense of our results and communicate them to other people, we need to add some more annotation to our main `res` obect.

We will use two bioconductor packages to first map IDs to different formats, including the gene name.

```{r}
library(AnnotationDbi)
library(org.Hs.eg.db)
```

Let's see what is in `org.Hs.eg.db`

```{r}
columns(org.Hs.eg.db)
```

We can translate our gene IDs to the gene names in any of these 26 databases using the `mapIDs()` function

```{r}
res$symbol <- mapIds(keys = row.names(res), # Our current IDs
       keytype = "ENSEMBL",   # the format of our IDs
       x = org.Hs.eg.db,      # where to get the mappings from
       column = "SYMBOL"      # the format/DB to map to
       )
head(res)
```

Add the mappings for "GENENAME" and "ENTREZID" and store as `res$genename` and `res$entrez`

```{r}
res$genename <- mapIds(keys = row.names(res), # Our current IDs
       keytype = "ENSEMBL",   # the format of our IDs
       x = org.Hs.eg.db,      # where to get the mappings from
       column = "GENENAME"      # the format/DB to map to
       )
head(res)
```

```{r}
res$entrez <- mapIds(keys = row.names(res), # Our current IDs
       keytype = "ENSEMBL",   # the format of our IDs
       x = org.Hs.eg.db,      # where to get the mappings from
       column = "ENTREZID"      # the format/DB to map to
       )
head(res)
```

## Pathway analysis

There are a lot of packages for pathway analysis. For now, let's just try one of them called **gage**.

```{r, message = FALSE}
library(gage)
library(gageData)
library(pathview)
```

To use **gage** I need two things

- a named vector of fold-change values for our DEGs (our geneset of interest)
- a set of pathways for annotation

```{r}
foldchanges <- res$log2FoldChange
names(foldchanges) <- res$entrez # We need to use Entrez ID here for KEGG
head(foldchanges)
```

```{r}
data(kegg.sets.hs)
keggres = gage(foldchanges, gsets = kegg.sets.hs)
```

There are three attributes in othe results object
```{r}
attributes(keggres)
```


We can look into the top 5 pathways that are downregulated
```{r}
head(keggres$less, 5)
```
We can view one if these pathways (hsa05310 Asthma) with our genes colored, so we can see the overlap

```{r}
pathview(pathway.id = "hsa05310", gene.data = foldchanges)
```

Add this pathway figure to our lab report

![](hsa05310.pathview.png)

## Save our results

```{r}
write.csv(res, file = "myresults_annotated.csv")
```

